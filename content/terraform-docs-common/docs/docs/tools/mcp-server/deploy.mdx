---
page_title: Deploy the Terraform model context protocol (MCP) server 
description: |-
 Learn how to deploy the Terraform MCP server, which helps you write configuration using LLM responses sourced from the Terraform registry.
---

# Deploy the Terraform MCP server

The Terraform Model Context Protocol (MCP) server enables AI models to generate Terraform configuration using up-to-date information from the Terraform registry. This page explains how to install, configure, and integrate the server with your AI client.

@include 'beta.mdx'

## Overview

The Terraform MCP server is a specialized service that provides AI models with access to current Terraform provider documentation and module information. You can deploy the server in to the following environments:

- **Local deployment**: Run the server on your workstation using `stdio` mode for direct communication through standard input/output
- **Remote deployment**: Run the server on a remote instance using `streamable-http` mode for network-based communication

### Installation methods

Choose from three installation options based on your environment and preferences:

| Method | Best for | Requirements |
|--------|----------|--------------|
| [Docker](#run-in-docker) | Most users, consistent environments | Docker Engine v20.10.21+ or Docker Desktop v4.14.0+. Refer to the [Docker documentation](https://docs.docker.com/desktop) for installation instructions. |
| [Compiled binary](#run-the-compiled-binary) | Lightweight deployments, specific OS needs | Compatible operating system |
| [Source installation](#install-from-source) | Development, customization | Go development environment |

## Run in Docker

Docker provides the most reliable and consistent way to run the Terraform MCP server across different environments.

1. Start Docker on your system.

1. Integrate with your AI client:

    <Tabs>

    <Tab heading="Visual Studio Code">

    1. Verify [Visual Studio Code](https://code.visualstudio.com/docs) is installed.
    1. Verify the [GitHub Copilot extension](https://code.visualstudio.com/docs/copilot/overview) is installed and chats are configured to `Agent` mode.
    1. Verify MCP support enabled, refer to the [VS Code MCP documentation](https://code.visualstudio.com/docs/copilot/chat/mcp-servers) for more information.
    1. To use the MCP server in all workspaces, add the following configuration to your user settings JSON file:

    ```json
    {
      "mcp": {
        "servers": {
          "terraform": {
            "command": "docker",
            "args": [
              "run",
              "-i",
              "--rm",
              "hashicorp/terraform-mcp-server"
            ]
          }
        }
      }
    }
    ```

    1. Optional. To use the server in a specific workspace, create an `mcp.json` file with the following configuration in your workspace's `.vscode` directory:

    ```json
    {
      "servers": {
        "terraform": {
          "command": "docker",
          "args": [
            "run",
            "-i",
            "--rm",
            "hashicorp/terraform-mcp-server"
          ]
        }
      }
    }
    ```

    1. To verify the integration, open the chat interface and select **Agent** from the mode settings.
    1. Click the tools icon to verify that Terraform MCP server tools appear in the available tools list.
    
    </Tab>

    <Tab heading="Cursor">
    
    1. Verify [Cursor](https://www.cursor.com) is installed.
    1. Verify the MCP support configured, refer to [Cursor's MCP documentation](https://docs.cursor.com/context/model-context-protocol#configuring-mcp-servers) for more information.    
    1. To use the MCP server in all workspaces, add the following configuration to your user settings JSON file:
    
    ```json
    {
      "mcp": {
        "servers": {
          "terraform": {
            "command": "docker",
            "args": [
              "run",
              "-i",
              "--rm",
              "hashicorp/terraform-mcp-server"
            ]
          }
        }
      }
    }
    ```

    1. Optional. To use the server in a specific workspace, create an `mcp.json` file with the following configuration in your workspace's `.vscode` directory:
    
    ```json
    {
      "servers": {
        "terraform": {
          "command": "docker",
          "args": [
            "run",
            "-i",
            "--rm",
            "hashicorp/terraform-mcp-server"
          ]
        }
      }
    }
    ```

    1. To verify the installation, open the chat pane and select **Chat Settings** from the ellipses menu.
    1. Choose **Agent** from the **Default new chat mode** drop-down menu.
    1. Select **MCP** from the **Cursor Settings** sidebar to verify that Terraform MCP server tools are enabled.
    
    </Tab>
    
    <Tab heading="Claude Desktop">
    
    1. Verify [Claude Desktop](https://support.anthropic.com/en/articles/10065433-installing-claude-for-desktop) is installed.
    1. Verify MCP support is configured, refer to [Claude Desktop's MCP documentation](https://modelcontextprotocol.io/quickstart/user) for more information.    
    1. Create or edit the `mcp.json` file and add the following configuration:
     
    ```json
    {
      "mcpServers": {
        "servers": {
          "hcp-terraform": {
            "command": "docker",
            "args": [
              "run",
              "-i",
              "--rm",
              "hashicorp/terraform-mcp-server:<version>"
            ]
          }
        }
      }
    }
    ```
    
    1. To verify the integration, open the chat pane and click the **search and tools** slider icon.
    1. Click **terraform-mcp-server** to verify that all tools are enabled and accessible.
    
    </Tab>
    
    <Tab heading="Amazon Q">
    
    1. Verify [Amazon Q](https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-installing.html) is installed.
    1. Verify MCP support is configured, refer to [Amazon Q's MCP documentation](https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/qdev-mcp.html) for more information.    
    1. Create or edit the `mcp.json` file with the following configuration:
     
    ```json
    {
      "mcpServers": {
        "servers": {
          "hcp-terraform": {
            "command": "docker",
            "args": [
              "run",
              "-i",
              "--rm",
              "hashicorp/terraform-mcp-server:<version>"
            ]
          }
        }
      }
    }
    ```
    
    </Tab>
    
    </Tabs>

## Run the compiled binary

The compiled binary option provides a lightweight installation without Docker dependencies. This method is ideal when you want to minimize resource usage or work in environments with restricted container access.

1. Download the binary for your operating system and architecture, visit the [release library](https://releases.hashicorp.com/terraform-mcp-server).  
1. Add the following configuration to your client settings:

### Client configuration

1. Add the following configuration to your client settings:

    ```json
    {
      "mcp": {
        "servers": {
          "terraform": {
            "command": "/path/to/terraform-mcp-server",
            "args": ["stdio"]
          }
        }
      }
    }
    ```

1. Replace `/path/to/terraform-mcp-server` with the actual path to your downloaded binary.

## Install from source

Installing from source gives you access to the latest features and allows for customization. This method requires a Go development environment.

1. Run the following `go` command to install the latest stable release:

```shell-session
$ go install github.com/hashicorp/terraform-mcp-server/cmd/terraform-mcp-server@latest
```

1. Optional. Run the following `go` command to install the development version on `main`:

```shell-session
$ go install github.com/hashicorp/terraform-mcp-server/cmd/terraform-mcp-server@main
```

1. After installation, add the following configuration to your client:

```json
{
  "mcp": {
    "servers": {
      "terraform": {
        "command": "/path/to/terraform-mcp-server",
        "args": ["stdio"]
      }
    }
  }
}
```

The binary location depends on your Go installation and `GOPATH` configuration. Use `which terraform-mcp-server` to find the installed binary path.

## Configuration reference

You can configure the following settings so that MCP server operates correctly for your environment. 

### Transport protocols

|   Transport      |   Best for                                                      |   How it works                                                                                |   Usage                                                          |
|------------------|-----------------------------------------------------------------|-----------------------------------------------------------------------------------------------|------------------------------------------------------------------|
| `stdio`          | Local development and direct integration with MCP clients       | Uses standard input/output for JSON-RPC message communication                                 | Automatically used when no specific transport mode is configured |
| `streamableHTTP` | Remote deployments, distributed setups, production environments | HTTP-based transport with support for both direct HTTP requests                               | Enable by setting `TRANSPORT_MODE=streamable-http`               |


### Environment variables

Configure the server behavior using these environment variables:

| Variable             | Purpose                  | Default Value   | Example                  | Options                                 |
|----------------------|--------------------------|-----------------|--------------------------|-----------------------------------------|
| `TRANSPORT_MODE`     | Communication protocol   | `stdio`         | `streamable-http`        | `stdio`, `streamable-http`              |
| `TRANSPORT_HOST`     | HTTP server binding address | `127.0.0.1`  | `0.0.0.0`                | Any valid IP address                    |
| `TRANSPORT_PORT`     | HTTP server port         | `8080`          | `3000`                   | Any valid port number                   |
| `MCP_ENDPOINT`       | HTTP endpoint path       | `/mcp`          | `/api/mcp`               | Any valid endpoint path                 |
| `MCP_SESSION_MODE`   | Session management       | `stateful`      | `stateless`              | `stateful`, `stateless`                 |
| `MCP_ALLOWED_ORIGINS`| CORS allowed origins     | `""` (none)     | `https://app.terraform.io`| Comma-separated list of origins or `""` |
| `MCP_CORS_MODE`      | CORS policy enforcement  | `strict`        | `development`            | `strict`, `development`, `disabled`     |

### Command line interface

Control server behavior directly from the command line:

<Tab>
<Tab heading="stdio">

```bash
terraform-mcp-server stdio [--log-file /path/to/log]
```

</Tab>

<Tab heading="streamableHTTP">

```bash
terraform-mcp-server streamable-http \
  [--transport-port 8080] \
  [--transport-host 127.0.0.1] \
  [--mcp-endpoint /mcp] \
  [--log-file /path/to/log]
```

</Tab>
</Tabs>

## Next steps

You have successfully deployed the Terraform MCP server. The server is now ready to enhance your AI model's ability to generate accurate Terraform configurations using current provider documentation and module information.

- Begin prompting your AI model about Terraform configurations. Refer to [Prompt an AI model](/terraform/docs/tools/mcp-server/prompt) for guidance on effective prompting techniques.
- The server provides access to up-to-date provider documentation.
- Ask for help with specific Terraform resources and modules.
- Explore advanced configuration options for your specific deployment needs.
